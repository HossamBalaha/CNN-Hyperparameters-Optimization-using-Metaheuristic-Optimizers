{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN Hyperparameters Optimization using Metaheuristic Optimizers (Video).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Ignore Warnings"
      ],
      "metadata": {
        "id": "Md3o9RiEZa-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import logging\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "QHDxpK1eZdCn"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Acquisition"
      ],
      "metadata": {
        "id": "_hDsFSCR_knX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "metadata": {
        "id": "6vmtIgJvALJg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ndt2Zrng-g9i"
      },
      "outputs": [],
      "source": [
        "PROJECT_PATH = \"/content/drive/MyDrive/CNN Hyperparameters Optimization using Metaheuristic Optimizers\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = PROJECT_PATH"
      ],
      "metadata": {
        "id": "2bgob5tMAYM8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/CNN Hyperparameters Optimization using Metaheuristic Optimizers\n",
        "!kaggle datasets download -d alifrahman/covid19-chest-xray-image-dataset"
      ],
      "metadata": {
        "id": "jIlhnLnHAsnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q covid19-chest-xray-image-dataset.zip -d \"COVID-19 Chest X-ray Image Dataset\""
      ],
      "metadata": {
        "id": "wnKagn_WA2qd"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configurations"
      ],
      "metadata": {
        "id": "nwfWLVqMCL6b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_PATH = \"/content/drive/MyDrive/CNN Hyperparameters Optimization using Metaheuristic Optimizers/COVID-19 Chest X-ray Image Dataset/dataset\"\n",
        "CLASSES = [\"normal\", \"covid\"]\n",
        "NEW_SIZE = (32, 32, 3)\n",
        "TRAIN_SIZE = 0.8\n",
        "POPULATION_SIZE = 5\n",
        "NO_OF_ITERATIONS = 3\n",
        "LOWER_BOUND = 0.0\n",
        "UPPER_BOUND = 1.0\n",
        "EPOCHS = 15\n",
        "PATIENCE = 7"
      ],
      "metadata": {
        "id": "P6rSV4ykCHOA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ],
      "metadata": {
        "id": "1-qidh1eELEd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def DisplayColorImage(image):\n",
        "  newImage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "  f = plt.figure()\n",
        "  plt.imshow(newImage)\n",
        "  plt.show()\n",
        "  plt.close()\n",
        "\n",
        "def PlotHistory(history):\n",
        "  f = plt.figure()\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title(\"Accuracy Curve\")\n",
        "  plt.xlabel(\"Epoch\")\n",
        "  plt.ylabel(\"Accuracy\")\n",
        "  plt.legend([\"Train\", \"Validation\"])\n",
        "  plt.grid(\"both\")\n",
        "  plt.show()\n",
        "  plt.close()"
      ],
      "metadata": {
        "id": "9BMQo70CEOZu"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading Dataset"
      ],
      "metadata": {
        "id": "KlfjfLbeCYjR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2, os\n",
        "X = []\n",
        "y = []\n",
        "counter = {\"covid\": 0, \"normal\": 0}\n",
        "\n",
        "for cls in CLASSES:\n",
        "  clsContent = os.listdir(os.path.join(DATASET_PATH, cls))\n",
        "  for imgName in clsContent:\n",
        "    imgPath = os.path.join(DATASET_PATH, cls, imgName)\n",
        "    image = cv2.imread(imgPath)\n",
        "    image = cv2.resize(image, NEW_SIZE[:2], interpolation=cv2.INTER_CUBIC)\n",
        "    X.append(image)\n",
        "    y.append(cls)\n",
        "    counter[cls] += 1\n",
        "\n",
        "print(len(X), len(y))\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "C9pxzN1kCfFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DisplayColorImage(X[0])"
      ],
      "metadata": {
        "id": "ck-k9WSOC6fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Balancing"
      ],
      "metadata": {
        "id": "VRvNTk5OFe67"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "dataGen = ImageDataGenerator(\n",
        "  rotation_range=25,\n",
        "  width_shift_range=0.2,\n",
        "  height_shift_range=0.2,\n",
        "  zoom_range=0.2,\n",
        "  shear_range=0.2,\n",
        "  horizontal_flip=True,\n",
        "  vertical_flip=True,\n",
        ")"
      ],
      "metadata": {
        "id": "-lPXE3C3Euca"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normalX = [X[i] for i in range(len(X)) if y[i] == \"normal\"]\n",
        "dataGen.fit(normalX)"
      ],
      "metadata": {
        "id": "P1iAMcftFvIk"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "diff = counter[\"covid\"] - counter[\"normal\"]\n",
        "imgGenerator = dataGen.flow(np.array(normalX), batch_size=1)\n",
        "newImage = next(imgGenerator)[0].astype(\"uint8\")\n",
        "print(newImage.shape)\n",
        "DisplayColorImage(newImage)\n",
        "# print(newImage)"
      ],
      "metadata": {
        "id": "t2eWWetTGX2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(diff):\n",
        "  newImage = next(imgGenerator)[0].astype(\"uint8\")\n",
        "  X.append(newImage)\n",
        "  y.append(\"normal\")\n",
        "  counter[\"normal\"] += 1\n",
        "\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "gZvbwN5BGfFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Scaling"
      ],
      "metadata": {
        "id": "zWhRicirIAm9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(X) / 255.0 # Normalization"
      ],
      "metadata": {
        "id": "BScDL3rUH2RV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Label Encoding"
      ],
      "metadata": {
        "id": "TjxEAHxnIS3_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "objEnc = LabelEncoder()\n",
        "yEnc = objEnc.fit_transform(y)\n",
        "print(y[0], yEnc[0])"
      ],
      "metadata": {
        "id": "KzGuF92VIaJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Split"
      ],
      "metadata": {
        "id": "icMyC9XkIuE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "trainX, testX, trainY, testY = train_test_split(np.array(X), yEnc, train_size=TRAIN_SIZE, stratify=yEnc)\n",
        "trainX, valX, trainY, valY = train_test_split(trainX, trainY, train_size=TRAIN_SIZE, stratify=trainY)\n",
        "print(trainX.shape)\n",
        "print(testX.shape)\n",
        "print(valX.shape)"
      ],
      "metadata": {
        "id": "Lk9lHDoMIpeK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Learning and Optimization"
      ],
      "metadata": {
        "id": "tDNdyXzSJ_Vw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import *\n",
        "\n",
        "ranges = {\n",
        "  \"Rotation\": np.arange(0, 31, 1),\n",
        "  \"Width Shift\": np.arange(0, 0.21, 0.1),\n",
        "  \"Height Shift\": np.arange(0, 0.21, 0.1),\n",
        "  \"Zoom\": np.arange(0, 0.21, 0.1),\n",
        "  \"Shear\": np.arange(0, 0.21, 0.1),\n",
        "  \"Horizontal Flip\": [True, False],\n",
        "  \"Vertical Flip\": [True, False],\n",
        "  \"Optimizer\": [Adam(), Nadam(), RMSprop(), Adadelta(), Adagrad(), SGD()],\n",
        "  \"Batch Size\": [8, 16, 32, 64],\n",
        "  \"TL Learn Ratio\": np.arange(0, 26, 1),\n",
        "}\n",
        "\n",
        "SOLUTION_SIZE = len(ranges.keys())"
      ],
      "metadata": {
        "id": "z_dCaln_KlJ6"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Population Initialization\n",
        "population = np.random.uniform(\n",
        "  low=LOWER_BOUND,\n",
        "  high=UPPER_BOUND,\n",
        "  size=(POPULATION_SIZE, SOLUTION_SIZE)\n",
        ")\n",
        "print(population.shape)\n",
        "print(population[0])"
      ],
      "metadata": {
        "id": "D7rci7OUMGGq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.applications.mobilenet import MobileNet\n",
        "from tensorflow.keras.models import *\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.metrics import *\n",
        "from tensorflow.keras.callbacks import *\n",
        "\n",
        "# Fitness Function Evaluation\n",
        "def FitnessFunction(solution):\n",
        "  solution = np.round(solution, 4)\n",
        "\n",
        "  index = int(np.round(solution[0] * (len(ranges[\"Rotation\"]) - 1)))\n",
        "  rotationValue = ranges[\"Rotation\"][index]\n",
        "\n",
        "  index = int(np.round(solution[1] * (len(ranges[\"Width Shift\"]) - 1)))\n",
        "  widthShiftValue = ranges[\"Width Shift\"][index]\n",
        "\n",
        "  index = int(np.round(solution[2] * (len(ranges[\"Height Shift\"]) - 1)))\n",
        "  heightShiftValue = ranges[\"Height Shift\"][index]\n",
        "\n",
        "  index = int(np.round(solution[3] * (len(ranges[\"Zoom\"]) - 1)))\n",
        "  zoomValue = ranges[\"Zoom\"][index]\n",
        "\n",
        "  index = int(np.round(solution[4] * (len(ranges[\"Shear\"]) - 1)))\n",
        "  shearValue = ranges[\"Shear\"][index]\n",
        "\n",
        "  index = int(np.round(solution[5] * (len(ranges[\"Horizontal Flip\"]) - 1)))\n",
        "  hFlipValue = ranges[\"Horizontal Flip\"][index]\n",
        "\n",
        "  index = int(np.round(solution[6] * (len(ranges[\"Vertical Flip\"]) - 1)))\n",
        "  vFlipValue = ranges[\"Vertical Flip\"][index]\n",
        "\n",
        "  index = int(np.round(solution[7] * (len(ranges[\"Optimizer\"]) - 1)))\n",
        "  optimizerValue = ranges[\"Optimizer\"][index]\n",
        "\n",
        "  index = int(np.round(solution[8] * (len(ranges[\"Batch Size\"]) - 1)))\n",
        "  batchSizeValue = ranges[\"Batch Size\"][index]\n",
        "\n",
        "  index = int(np.round(solution[9] * (len(ranges[\"TL Learn Ratio\"]) - 1)))\n",
        "  tlLearnRatioValue = ranges[\"TL Learn Ratio\"][index]\n",
        "\n",
        "  dataGen = ImageDataGenerator(\n",
        "    rotation_range=rotationValue,\n",
        "    width_shift_range=widthShiftValue,\n",
        "    height_shift_range=heightShiftValue,\n",
        "    zoom_range=zoomValue,\n",
        "    shear_range=shearValue,\n",
        "    horizontal_flip=hFlipValue,\n",
        "    vertical_flip=vFlipValue,\n",
        "  )\n",
        "\n",
        "  baseModel = MobileNet(weights='imagenet', include_top=False, input_tensor=Input(NEW_SIZE))\n",
        "\n",
        "  x = baseModel.output\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  x = Dense(1024, activation='relu')(x)\n",
        "  predictions = Dense(1, activation='sigmoid')(x)\n",
        "\n",
        "  model = Model(inputs=baseModel.input, outputs=predictions)\n",
        "\n",
        "  for layer in baseModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "  fromIndex = int(np.round((len(baseModel.layers) - 1) * (1.0 - tlLearnRatioValue / 100.0)))\n",
        "  for layer in baseModel.layers[fromIndex:]:\n",
        "    layer.trainable = True\n",
        "\n",
        "  model.compile(\n",
        "    optimizer=optimizerValue, \n",
        "    loss='binary_crossentropy',\n",
        "    metrics=[\"accuracy\", Precision(), Recall(), AUC(), TruePositives(), TrueNegatives(), FalsePositives(), FalseNegatives()]\n",
        "  )\n",
        "\n",
        "  keyword = \"MobileNet-\" + \"-\".join([str(el)[2:] for el in solution])\n",
        "  checkpointPath = os.path.join(PROJECT_PATH, \"Checkpoints\", keyword) + \".h5\"\n",
        "  csvLogPath = os.path.join(PROJECT_PATH, \"Logs\", keyword) + \".csv\"\n",
        "\n",
        "  histroy = model.fit(\n",
        "    dataGen.flow(trainX, trainY, batch_size=batchSizeValue),\n",
        "    validation_data=(valX, valY),\n",
        "    batch_size=batchSizeValue,\n",
        "    epochs=EPOCHS,\n",
        "    verbose=0,\n",
        "    callbacks=[\n",
        "      ModelCheckpoint(checkpointPath, save_best_only=True, save_weights_only=True, monitor=\"val_accuracy\", mode=\"max\", verbose=0),\n",
        "      TerminateOnNaN(),\n",
        "      CSVLogger(csvLogPath, append=True),\n",
        "      EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", patience=PATIENCE),\n",
        "    ]\n",
        "  )\n",
        "\n",
        "  PlotHistory(histroy)\n",
        "\n",
        "  model.load_weights(checkpointPath)\n",
        "  scoresList = model.evaluate(testX, testY, verbose=0)\n",
        "  score = (scoresList[1] + scoresList[2] + scoresList[3]) / 3.0\n",
        "\n",
        "  configs = [\n",
        "    rotationValue,\n",
        "    widthShiftValue,\n",
        "    heightShiftValue,\n",
        "    zoomValue,\n",
        "    shearValue,\n",
        "    hFlipValue,\n",
        "    vFlipValue,\n",
        "    optimizerValue._name,\n",
        "    batchSizeValue,\n",
        "    tlLearnRatioValue,\n",
        "  ]\n",
        "  print(scoresList, score, configs)\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "DrXOWkFsNBkI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Population Updating\n",
        "def PopulationUpdating(population, scores, iterationNumber):\n",
        "  bestIndex = np.argmax(scores)\n",
        "  bestSolution = population[bestIndex].copy()\n",
        "  bestScore = scores[bestIndex]\n",
        "\n",
        "  # MRFO:\n",
        "  # Write the metaheuristic rules for updating the population.\n",
        "  newPopulation = population.copy()\n",
        "\n",
        "  coef = iterationNumber / float(NO_OF_ITERATIONS)\n",
        "  for i in range(len(population)):\n",
        "    r = np.random.random(1)\n",
        "    alpha = 2.0 * r * np.sqrt(np.abs(np.log(r)))\n",
        "    r1 = np.random.random(1)\n",
        "    factor = (NO_OF_ITERATIONS - iterationNumber + 1.0) / (NO_OF_ITERATIONS * 1.0)\n",
        "    beta = 2.0 * np.exp(r1 * factor) * np.sin(2.0 * np.pi * r1)\n",
        "    if (np.random.random(1) < 0.5):\n",
        "      if (coef < np.random.random(1)):\n",
        "        s = np.subtract(UPPER_BOUND, LOWER_BOUND)\n",
        "        u = np.random.uniform(low=0, high=1, size=SOLUTION_SIZE)\n",
        "        m = np.multiply(u, s)\n",
        "        xRand = np.clip(np.add(LOWER_BOUND, m), LOWER_BOUND, UPPER_BOUND)\n",
        "        if (i == 0):\n",
        "          newPopulation[i, :] = xRand + r * (xRand - population[i, :]) + beta * (xRand - population[i, :])\n",
        "        else:\n",
        "          newPopulation[i, :] = xRand + r * (population[i - 1, :] - population[i, :]) + beta * (xRand - population[i, :])\n",
        "      else:\n",
        "        if (i == 0):\n",
        "          newPopulation[i, :] = bestSolution + r * (bestSolution - population[i, :]) + beta * (bestSolution - population[i, :])\n",
        "        else:\n",
        "          newPopulation[i, :] = bestSolution + r * (population[i - 1, :] - population[i, :]) + beta * (bestSolution - population[i, :])\n",
        "    else:\n",
        "      if (i == 0):\n",
        "        newPopulation[i, :] = population[i, :] + r * (bestSolution - population[i, :]) + alpha * (bestSolution - population[i, :])\n",
        "      else:\n",
        "        newPopulation[i, :] = population[i, :] + r * (population[i - 1, :] - population[i, :]) + alpha * (bestSolution - population[i, :])\n",
        "    \n",
        "    newPopulation[i, :] = np.clip(newPopulation[i, :], LOWER_BOUND, UPPER_BOUND)\n",
        "    \n",
        "    currentScore = FitnessFunction(newPopulation[i, :])\n",
        "    if (currentScore > bestScore):\n",
        "      bestSolution, bestScore = newPopulation[i, :].copy(), currentScore\n",
        "    \n",
        "    s = 2.0\n",
        "    r2, r3 = np.random.random(1), np.random.random(1)\n",
        "    newPopulation[i, :] = population[i, :] + s * (r2 * bestSolution - r3 * population[i, :])\n",
        "    \n",
        "    newPopulation[i, :] = np.clip(newPopulation[i, :], LOWER_BOUND, UPPER_BOUND)\n",
        "    \n",
        "    currentScore = FitnessFunction(newPopulation[i, :])\n",
        "    if (currentScore > bestScore):\n",
        "      bestSolution, bestScore = newPopulation[i, :].copy(), currentScore\n",
        "\n",
        "  return newPopulation.copy()"
      ],
      "metadata": {
        "id": "gFGE7owoNj6z"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Repeat\n",
        "bestSolutions = []\n",
        "bestScores = []\n",
        "for iterationNumber in range(NO_OF_ITERATIONS):\n",
        "  scores = []\n",
        "  for i in range(len(population)):\n",
        "    score = FitnessFunction(population[i])\n",
        "    scores.append(score)\n",
        "\n",
        "  newPopulation = PopulationUpdating(population, scores, iterationNumber)\n",
        "  \n",
        "  # LOGGING THE DATA\n",
        "  populationScoresPath = os.path.join(PROJECT_PATH, \"Population.csv\")\n",
        "  # T #, S #, ......, Score\n",
        "  file = open(populationScoresPath, \"a\")\n",
        "  for i in range(len(population)):\n",
        "    data = f\"{iterationNumber + 1},{i + 1},\"\n",
        "    data += \",\".join([str(el) for el in population[i]])\n",
        "    data += f\",{scores[i]}\"\n",
        "    data += \"\\n\"\n",
        "    file.write(data)\n",
        "  file.close()\n",
        "\n",
        "  bestIndex = np.argmax(scores)\n",
        "  bestSolution = population[bestIndex].copy()\n",
        "  bestScore = scores[bestIndex]\n",
        "  bestSolutions.append(bestSolution)\n",
        "  bestScores.append(bestScore)\n",
        "  \n",
        "  population = newPopulation.copy()"
      ],
      "metadata": {
        "id": "-flZHEVCJpoW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LOGGING THE DATA\n",
        "bestSolutionsPath = os.path.join(PROJECT_PATH, \"BestSolutions.csv\")\n",
        "file = open(bestSolutionsPath, \"w\")\n",
        "for i in range(len(bestSolutions)):\n",
        "  data = \",\".join([str(el) for el in bestSolutions[i]])\n",
        "  data += f\",{bestScores[i]}\"\n",
        "  data += \"\\n\"\n",
        "  file.write(data)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "lHTfNh3YRKgt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4Kn74BHFRMlo"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}